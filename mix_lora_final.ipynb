{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import bitsandbytes as bnb\n",
    "import argparse\n",
    "\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from trl import setup_chat_format, SFTConfig, SFTTrainer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# set the wandb project where this run will be logged\n",
    "os.environ[\"WANDB_PROJECT\"]=\"cs769_llama\"\n",
    "# turn off watch to log faster\n",
    "os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "HF_TOKEN = \"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\"\n",
    "base_model_name = \"meta-llama/Llama-3.2-3b-Instruct\"\n",
    "root_model_dir = \"LoraModel\"\n",
    "dataset_name = 'openlifescienceai/medmcqa'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_name,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "def format_chat_template(row):\n",
    "\n",
    "    instruction = \"\"\"\n",
    "    Answer the following multiple choice question by giving the most appropriate response. \n",
    "    Answer should be one among [A, B, C, D].\n",
    "    \"\"\"\n",
    "\n",
    "    idx_to_ans_map = {0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
    "\n",
    "    a = row['opa']\n",
    "    b = row['opb']\n",
    "    c = row['opc']\n",
    "    d = row['opd']\n",
    "\n",
    "    user_instruction = f\"\"\"Question: {row['question']}\n",
    "                A) {a}\n",
    "                B) {b}\n",
    "                C) {c}\n",
    "                D) {d}\n",
    "            \"\"\"\n",
    "\n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction },\n",
    "               {\"role\": \"user\", \"content\": user_instruction },\n",
    "               {\"role\": \"assistant\", \"content\": idx_to_ans_map[row['cop']]}]\n",
    "    \n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "def create_lora_model(base_model, difficulty, modules):\n",
    "    rank_map = {'easy': 8, 'medium': 16, 'hard': 32}\n",
    "    alpha_map = {'easy': 16, 'medium': 32, 'hard': 64}\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "            r=rank_map[difficulty],\n",
    "            lora_alpha=alpha_map[difficulty],\n",
    "            target_modules=modules,\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "    \n",
    "    return peft_config, get_peft_model(\n",
    "        base_model,\n",
    "        peft_config\n",
    "    )\n",
    "\n",
    "\n",
    "def train_adapter(model_dir, run_name, bnb_config, difficulty_level, train_data, val_data, peft_model, peft_config):\n",
    "    \n",
    "    print(f\"Parameters for the {difficulty} LoRA model: \")\n",
    "    peft_model.print_trainable_parameters()\n",
    "\n",
    "    training_arguments = SFTConfig(\n",
    "        output_dir=f\"./{model_dir}/{difficulty_level}\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=2,\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        num_train_epochs=2,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=250,\n",
    "        logging_steps=250,\n",
    "        warmup_ratio=0.03,\n",
    "        logging_strategy='steps',\n",
    "        learning_rate=2e-4,\n",
    "        fp16=False,\n",
    "        bf16=False,\n",
    "        group_by_length=True,\n",
    "        remove_unused_columns=True,\n",
    "        report_to='wandb',\n",
    "        run_name=run_name,\n",
    "        max_seq_length=512,\n",
    "        dataset_text_field='text',\n",
    "        label_names=[\"labels\"],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False        \n",
    "    )\n",
    "    trainer = SFTTrainer(\n",
    "        model=peft_model,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        peft_config=peft_config,\n",
    "        processing_class=tokenizer,\n",
    "        args=training_arguments,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    peft_model.save_pretrained(os.path.join(model_dir, f'{difficulty_level}_best')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its better to load from the checkpoint with lowest loss\n",
    "# as 'load_best_model_at_end' is dependent on a compute_metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 38800/38800 [00:06<00:00, 5779.70 examples/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for the easy LoRA model: \n",
      "trainable params: 12,156,928 || all params: 3,224,906,752 || trainable%: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 38800/38800 [00:03<00:00, 11573.93 examples/s]\n",
      "Adding EOS to train dataset: 100%|██████████| 38800/38800 [00:03<00:00, 10254.30 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 38800/38800 [00:14<00:00, 2701.48 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 38800/38800 [00:00<00:00, 301948.36 examples/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyammohan2103\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/workspace/CS769/wandb/run-20250501_213927-0s38esrr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/syammohan2103/cs769_llama/runs/0s38esrr' target=\"_blank\">Lora_easy</a></strong> to <a href='https://wandb.ai/syammohan2103/cs769_llama' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/syammohan2103/cs769_llama' target=\"_blank\">https://wandb.ai/syammohan2103/cs769_llama</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/syammohan2103/cs769_llama/runs/0s38esrr' target=\"_blank\">https://wandb.ai/syammohan2103/cs769_llama/runs/0s38esrr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 1:45:23, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.947900</td>\n",
       "      <td>0.850179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.839680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.830932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.826586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.828990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>0.830467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.609400</td>\n",
       "      <td>0.826752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.613100</td>\n",
       "      <td>0.826002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.603900</td>\n",
       "      <td>0.826664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\n",
    "    #     \"--difficulty\",\n",
    "    #     choices=[\"easy\",\"medium\",\"hard\"],\n",
    "    #     required=True,\n",
    "    #     help=\"Which subset (easy/medium/hard) to fine-tune\"\n",
    "    # )\n",
    "    # args = parser.parse_args()\n",
    "    # difficulty = args.difficulty\n",
    "    difficulty = 'easy'\n",
    "\n",
    "    # hack to handle data errors while using map function\n",
    "    if difficulty == 'easy':\n",
    "        easy_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset1')))\n",
    "        train_dataset = easy_data.map(format_chat_template)\n",
    "    elif difficulty == 'medium':\n",
    "        medium_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset2')))\n",
    "        train_dataset = medium_data.map(format_chat_template)\n",
    "    elif difficulty == 'hard':\n",
    "        hard_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset3')))\n",
    "        train_dataset = hard_data.map(format_chat_template)\n",
    "\n",
    "    val_data = load_dataset(dataset_name, split='validation', trust_remote_code=True)\n",
    "    val_dataset = val_data.map(format_chat_template)\n",
    "\n",
    "    # Use existing global bnb_config defined earlier\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "    base_model = prepare_model_for_kbit_training(base_model)\n",
    "    modules = find_all_linear_names(base_model)\n",
    "    peft_config, peft_model = create_lora_model(base_model, difficulty, modules)\n",
    "\n",
    "    train_adapter(\n",
    "            model_dir=\"LoRA‐MedQA\",\n",
    "            run_name=f'Lora_{difficulty}',\n",
    "            bnb_config=bnb_config,\n",
    "            difficulty_level=difficulty,\n",
    "            train_data=train_dataset,\n",
    "            val_data=val_dataset,\n",
    "            peft_model=peft_model,\n",
    "            peft_config=peft_config\n",
    "        )\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 73332/73332 [00:14<00:00, 4999.56 examples/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for the medium LoRA model: \n",
      "trainable params: 24,313,856 || all params: 3,237,063,680 || trainable%: 0.7511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 73332/73332 [00:08<00:00, 9003.69 examples/s] \n",
      "Adding EOS to train dataset: 100%|██████████| 73332/73332 [00:08<00:00, 8801.17 examples/s] \n",
      "Tokenizing train dataset: 100%|██████████| 73332/73332 [00:27<00:00, 2678.52 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 73332/73332 [00:00<00:00, 277533.43 examples/s]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1192160/1220316256.py\", line 39, in <module>\n",
      "    train_adapter(\n",
      "  File \"/tmp/ipykernel_1192160/817838319.py\", line 100, in train_adapter\n",
      "    trainer.train()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2469, in _inner_training_loop\n",
      "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 506, in on_train_begin\n",
      "    return self.call_event(\"on_train_begin\", args, state, control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 556, in call_event\n",
      "    result = getattr(callback, event)(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 930, in on_train_begin\n",
      "    self.setup(args, state, model, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 862, in setup\n",
      "    self._wandb.config.update(combined_dict, allow_val_change=True)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_config.py\", line 189, in update\n",
      "    self._callback(data=sanitized)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 406, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 464, in wrapper_fn\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1429, in _config_callback\n",
      "    logger.info(f\"config_cb {key} {val} {data}\")\n",
      "Message: \"config_cb None None {'peft_config': {'default': {'task_type': 'CAUSAL_LM', 'peft_type': <PeftType.LORA: 'LORA'>, 'auto_mapping': None, 'base_model_name_or_path': 'meta-llama/Llama-3.2-3b-Instruct', 'revision': None, 'inference_mode': False, 'r': 16, 'target_modules': {'down_proj', 'v_proj', 'o_proj', 'up_proj', 'q_proj', 'gate_proj', 'k_proj'}, 'exclude_modules': None, 'lora_alpha': 32, 'lora_dropout': 0.05, 'fan_in_fan_out': False, 'bias': 'none', 'use_rslora': False, 'modules_to_save': None, 'init_lora_weights': True, 'layers_to_transform': None, 'layers_pattern': None, 'rank_pattern': {}, 'alpha_pattern': {}, 'megatron_config': None, 'megatron_core': 'megatron.core', 'trainable_token_indices': None, 'loftq_config': {}, 'eva_config': None, 'corda_config': None, 'use_dora': False, 'layer_replication': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'lora_bias': False}}, 'vocab_size': 128256, 'max_position_embeddings': 131072, 'hidden_size': 3072, 'intermediate_size': 8192, 'num_hidden_layers': 28, 'num_attention_heads': 24, 'num_key_value_heads': 8, 'hidden_act': 'silu', 'initializer_range': 0.02, 'rms_norm_eps': 1e-05, 'pretraining_tp': 1, 'use_cache': True, 'rope_theta': 500000.0, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'attention_bias': False, 'attention_dropout': 0.0, 'mlp_bias': False, 'head_dim': 128, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float16', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 512, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['LlamaForCausalLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 128000, 'pad_token_id': None, 'eos_token_id': [128001, 128008, 128009], 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'meta-llama/Llama-3.2-3b-Instruct', '_attn_implementation_autoset': True, 'transformers_version': '4.51.3', 'model_type': 'llama', 'quantization_config': {'quant_method': 'BITS_AND_BYTES', '_load_in_8bit': False, '_load_in_4bit': True, 'llm_int8_threshold': 6.0, 'llm_int8_skip_modules': None, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'load_in_4bit': True, 'load_in_8bit': False}, 'output_dir': './LoRA‐MedQA/medium', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'eval_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 2, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 0.0002, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.03, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': './LoRA‐MedQA/medium/runs/May01_23-25-46_torch-llama-workspace2-0-0', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 250, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 250, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'Lora_medium', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': ['labels'], 'load_best_model_at_end': True, 'metric_for_best_model': 'eval_loss', 'greater_is_better': False, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'tp_size': 0, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'paged_adamw_32bit', 'optim_args': None, 'adafactor': False, 'group_by_length': True, 'length_column_name': 'length', 'report_to': ['wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': None, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False, 'average_tokens_across_devices': False, 'model_init_kwargs': None, 'dataset_text_field': 'text', 'dataset_kwargs': None, 'dataset_num_proc': None, 'eos_token': '<EOS_TOKEN>', 'pad_token': '<PAD_TOKEN>', 'packing': False, 'padding_free': False, 'eval_packing': None, 'completion_only_loss': None, 'dataset_batch_size': None, 'num_of_sequences': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'max_seq_length': 512, 'use_liger': None}\"\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1192160/1220316256.py\", line 39, in <module>\n",
      "    train_adapter(\n",
      "  File \"/tmp/ipykernel_1192160/817838319.py\", line 100, in train_adapter\n",
      "    trainer.train()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2469, in _inner_training_loop\n",
      "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 506, in on_train_begin\n",
      "    return self.call_event(\"on_train_begin\", args, state, control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 556, in call_event\n",
      "    result = getattr(callback, event)(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 930, in on_train_begin\n",
      "    self.setup(args, state, model, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 877, in setup\n",
      "    self._wandb.config[\"model/num_parameters\"] = model.num_parameters()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_config.py\", line 154, in __setitem__\n",
      "    logger.info(\"config set %s = %s - %s\", key, val, self._callback)\n",
      "Message: 'config set %s = %s - %s'\n",
      "Arguments: ('model/num_parameters', 3237063680, <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x7ffb839a5900>>)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1192160/1220316256.py\", line 39, in <module>\n",
      "    train_adapter(\n",
      "  File \"/tmp/ipykernel_1192160/817838319.py\", line 100, in train_adapter\n",
      "    trainer.train()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2469, in _inner_training_loop\n",
      "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 506, in on_train_begin\n",
      "    return self.call_event(\"on_train_begin\", args, state, control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 556, in call_event\n",
      "    result = getattr(callback, event)(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 930, in on_train_begin\n",
      "    self.setup(args, state, model, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 877, in setup\n",
      "    self._wandb.config[\"model/num_parameters\"] = model.num_parameters()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_config.py\", line 156, in __setitem__\n",
      "    self._callback(key=key, val=val)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 406, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 464, in wrapper_fn\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1429, in _config_callback\n",
      "    logger.info(f\"config_cb {key} {val} {data}\")\n",
      "Message: 'config_cb model/num_parameters 3237063680 None'\n",
      "Arguments: ()\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4584' max='4584' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4584/4584 3:18:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.929200</td>\n",
       "      <td>0.852860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.673600</td>\n",
       "      <td>0.839264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.828662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>0.819119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.642700</td>\n",
       "      <td>0.815195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.633900</td>\n",
       "      <td>0.811214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>0.807913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.806324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.619400</td>\n",
       "      <td>0.800325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.568300</td>\n",
       "      <td>0.815402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.551700</td>\n",
       "      <td>0.815806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.545800</td>\n",
       "      <td>0.814971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>0.812022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>0.812041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.811309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.810600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.532200</td>\n",
       "      <td>0.808617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.808625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3083, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/events.py\", line 82, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 613, in _post_run_cell_hook\n",
      "    self._logger.info(\"resuming backend\")\n",
      "Message: 'resuming backend'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\n",
    "    #     \"--difficulty\",\n",
    "    #     choices=[\"easy\",\"medium\",\"hard\"],\n",
    "    #     required=True,\n",
    "    #     help=\"Which subset (easy/medium/hard) to fine-tune\"\n",
    "    # )\n",
    "    # args = parser.parse_args()\n",
    "    # difficulty = args.difficulty\n",
    "    difficulty = 'medium'\n",
    "\n",
    "    # hack to handle data errors while using map function\n",
    "    if difficulty == 'easy':\n",
    "        easy_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset1')))\n",
    "        train_dataset = easy_data.map(format_chat_template)\n",
    "    elif difficulty == 'medium':\n",
    "        medium_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset2')))\n",
    "        train_dataset = medium_data.map(format_chat_template)\n",
    "    elif difficulty == 'hard':\n",
    "        hard_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset3')))\n",
    "        train_dataset = hard_data.map(format_chat_template)\n",
    "\n",
    "    val_data = load_dataset(dataset_name, split='validation', trust_remote_code=True)\n",
    "    val_dataset = val_data.map(format_chat_template)\n",
    "\n",
    "    # Use existing global bnb_config defined earlier\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "    base_model = prepare_model_for_kbit_training(base_model)\n",
    "    modules = find_all_linear_names(base_model)\n",
    "    peft_config, peft_model = create_lora_model(base_model, difficulty, modules)\n",
    "\n",
    "    train_adapter(\n",
    "            model_dir=\"LoRA‐MedQA\",\n",
    "            run_name=f'Lora_{difficulty}',\n",
    "            bnb_config=bnb_config,\n",
    "            difficulty_level=difficulty,\n",
    "            train_data=train_dataset,\n",
    "            val_data=val_dataset,\n",
    "            peft_model=peft_model,\n",
    "            peft_config=peft_config\n",
    "        )\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_cell_async\n",
      "    self.events.trigger('pre_run_cell', info)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/events.py\", line 82, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 596, in _pre_run_cell_hook\n",
      "    if self.notebook and self.notebook.save_ipynb():\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/jupyter.py\", line 401, in save_ipynb\n",
      "    logger.info(\"not saving jupyter notebook\")\n",
      "Message: 'not saving jupyter notebook'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_cell_async\n",
      "    self.events.trigger('pre_run_cell', info)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/events.py\", line 82, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 602, in _pre_run_cell_hook\n",
      "    self._logger.info(\"pausing backend\")\n",
      "Message: 'pausing backend'\n",
      "Arguments: ()\n",
      "Map: 100%|██████████| 70690/70690 [00:13<00:00, 5357.10 examples/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for the hard LoRA model: \n",
      "trainable params: 48,627,712 || all params: 3,261,377,536 || trainable%: 1.4910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train dataset to ChatML: 100%|██████████| 70690/70690 [00:07<00:00, 9094.37 examples/s] \n",
      "Adding EOS to train dataset: 100%|██████████| 70690/70690 [00:06<00:00, 10281.18 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 70690/70690 [00:28<00:00, 2520.24 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 70690/70690 [00:00<00:00, 287558.60 examples/s]\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1192160/941178437.py\", line 39, in <module>\n",
      "    train_adapter(\n",
      "  File \"/tmp/ipykernel_1192160/817838319.py\", line 100, in train_adapter\n",
      "    trainer.train()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2469, in _inner_training_loop\n",
      "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 506, in on_train_begin\n",
      "    return self.call_event(\"on_train_begin\", args, state, control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 556, in call_event\n",
      "    result = getattr(callback, event)(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 930, in on_train_begin\n",
      "    self.setup(args, state, model, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 862, in setup\n",
      "    self._wandb.config.update(combined_dict, allow_val_change=True)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_config.py\", line 189, in update\n",
      "    self._callback(data=sanitized)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 406, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 464, in wrapper_fn\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1429, in _config_callback\n",
      "    logger.info(f\"config_cb {key} {val} {data}\")\n",
      "Message: \"config_cb None None {'peft_config': {'default': {'task_type': 'CAUSAL_LM', 'peft_type': <PeftType.LORA: 'LORA'>, 'auto_mapping': None, 'base_model_name_or_path': 'meta-llama/Llama-3.2-3b-Instruct', 'revision': None, 'inference_mode': False, 'r': 32, 'target_modules': {'down_proj', 'v_proj', 'o_proj', 'up_proj', 'q_proj', 'gate_proj', 'k_proj'}, 'exclude_modules': None, 'lora_alpha': 64, 'lora_dropout': 0.05, 'fan_in_fan_out': False, 'bias': 'none', 'use_rslora': False, 'modules_to_save': None, 'init_lora_weights': True, 'layers_to_transform': None, 'layers_pattern': None, 'rank_pattern': {}, 'alpha_pattern': {}, 'megatron_config': None, 'megatron_core': 'megatron.core', 'trainable_token_indices': None, 'loftq_config': {}, 'eva_config': None, 'corda_config': None, 'use_dora': False, 'layer_replication': None, 'runtime_config': {'ephemeral_gpu_offload': False}, 'lora_bias': False}}, 'vocab_size': 128256, 'max_position_embeddings': 131072, 'hidden_size': 3072, 'intermediate_size': 8192, 'num_hidden_layers': 28, 'num_attention_heads': 24, 'num_key_value_heads': 8, 'hidden_act': 'silu', 'initializer_range': 0.02, 'rms_norm_eps': 1e-05, 'pretraining_tp': 1, 'use_cache': True, 'rope_theta': 500000.0, 'rope_scaling': {'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, 'attention_bias': False, 'attention_dropout': 0.0, 'mlp_bias': False, 'head_dim': 128, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': 'float16', 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 512, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['LlamaForCausalLM'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'bos_token_id': 128000, 'pad_token_id': None, 'eos_token_id': [128001, 128008, 128009], 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': 'meta-llama/Llama-3.2-3b-Instruct', '_attn_implementation_autoset': True, 'transformers_version': '4.51.3', 'model_type': 'llama', 'quantization_config': {'quant_method': 'BITS_AND_BYTES', '_load_in_8bit': False, '_load_in_4bit': True, 'llm_int8_threshold': 6.0, 'llm_int8_skip_modules': None, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'load_in_4bit': True, 'load_in_8bit': False}, 'output_dir': './LoRA‐MedQA/hard', 'overwrite_output_dir': False, 'do_train': False, 'do_eval': True, 'do_predict': False, 'eval_strategy': 'steps', 'prediction_loss_only': False, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 8, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 2, 'eval_accumulation_steps': None, 'eval_delay': 0, 'torch_empty_cache_steps': None, 'learning_rate': 0.0002, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 2, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'lr_scheduler_kwargs': {}, 'warmup_ratio': 0.03, 'warmup_steps': 0, 'log_level': 'passive', 'log_level_replica': 'warning', 'log_on_each_node': True, 'logging_dir': './LoRA‐MedQA/hard/runs/May02_02-46-28_torch-llama-workspace2-0-0', 'logging_strategy': 'steps', 'logging_first_step': False, 'logging_steps': 250, 'logging_nan_inf_filter': True, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': None, 'save_safetensors': True, 'save_on_each_node': False, 'save_only_model': False, 'restore_callback_states_from_checkpoint': False, 'no_cuda': False, 'use_cpu': False, 'use_mps_device': False, 'seed': 42, 'data_seed': None, 'jit_mode_eval': False, 'use_ipex': False, 'bf16': False, 'fp16': False, 'fp16_opt_level': 'O1', 'half_precision_backend': 'auto', 'bf16_full_eval': False, 'fp16_full_eval': False, 'tf32': None, 'local_rank': 0, 'ddp_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': False, 'eval_steps': 250, 'dataloader_num_workers': 0, 'dataloader_prefetch_factor': None, 'past_index': -1, 'run_name': 'Lora_hard', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': ['labels'], 'load_best_model_at_end': True, 'metric_for_best_model': 'eval_loss', 'greater_is_better': False, 'ignore_data_skip': False, 'fsdp': [], 'fsdp_min_num_params': 0, 'fsdp_config': {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, 'tp_size': 0, 'fsdp_transformer_layer_cls_to_wrap': None, 'accelerator_config': {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}, 'deepspeed': None, 'label_smoothing_factor': 0.0, 'optim': 'paged_adamw_32bit', 'optim_args': None, 'adafactor': False, 'group_by_length': True, 'length_column_name': 'length', 'report_to': ['wandb'], 'ddp_find_unused_parameters': None, 'ddp_bucket_cap_mb': None, 'ddp_broadcast_buffers': None, 'dataloader_pin_memory': True, 'dataloader_persistent_workers': False, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_token': '<HUB_TOKEN>', 'hub_private_repo': None, 'hub_always_push': False, 'gradient_checkpointing': False, 'gradient_checkpointing_kwargs': None, 'include_inputs_for_metrics': False, 'include_for_metrics': [], 'eval_do_concat_batches': True, 'fp16_backend': 'auto', 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>', 'mp_parameters': '', 'auto_find_batch_size': False, 'full_determinism': False, 'torchdynamo': None, 'ray_scope': 'last', 'ddp_timeout': 1800, 'torch_compile': False, 'torch_compile_backend': None, 'torch_compile_mode': None, 'include_tokens_per_second': False, 'include_num_input_tokens_seen': False, 'neftune_noise_alpha': None, 'optim_target_modules': None, 'batch_eval_metrics': False, 'eval_on_start': False, 'use_liger_kernel': False, 'eval_use_gather_object': False, 'average_tokens_across_devices': False, 'model_init_kwargs': None, 'dataset_text_field': 'text', 'dataset_kwargs': None, 'dataset_num_proc': None, 'eos_token': '<EOS_TOKEN>', 'pad_token': '<PAD_TOKEN>', 'packing': False, 'padding_free': False, 'eval_packing': None, 'completion_only_loss': None, 'dataset_batch_size': None, 'num_of_sequences': None, 'chars_per_token': '<CHARS_PER_TOKEN>', 'max_seq_length': 512, 'use_liger': None}\"\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1192160/941178437.py\", line 39, in <module>\n",
      "    train_adapter(\n",
      "  File \"/tmp/ipykernel_1192160/817838319.py\", line 100, in train_adapter\n",
      "    trainer.train()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2469, in _inner_training_loop\n",
      "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 506, in on_train_begin\n",
      "    return self.call_event(\"on_train_begin\", args, state, control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 556, in call_event\n",
      "    result = getattr(callback, event)(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 930, in on_train_begin\n",
      "    self.setup(args, state, model, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 877, in setup\n",
      "    self._wandb.config[\"model/num_parameters\"] = model.num_parameters()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_config.py\", line 154, in __setitem__\n",
      "    logger.info(\"config set %s = %s - %s\", key, val, self._callback)\n",
      "Message: 'config set %s = %s - %s'\n",
      "Arguments: ('model/num_parameters', 3261377536, <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x7ffb839a5900>>)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1192160/941178437.py\", line 39, in <module>\n",
      "    train_adapter(\n",
      "  File \"/tmp/ipykernel_1192160/817838319.py\", line 100, in train_adapter\n",
      "    trainer.train()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer.py\", line 2469, in _inner_training_loop\n",
      "    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 506, in on_train_begin\n",
      "    return self.call_event(\"on_train_begin\", args, state, control)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/trainer_callback.py\", line 556, in call_event\n",
      "    result = getattr(callback, event)(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 930, in on_train_begin\n",
      "    self.setup(args, state, model, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py\", line 877, in setup\n",
      "    self._wandb.config[\"model/num_parameters\"] = model.num_parameters()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_config.py\", line 156, in __setitem__\n",
      "    self._callback(key=key, val=val)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 406, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 464, in wrapper_fn\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 1429, in _config_callback\n",
      "    logger.info(f\"config_cb {key} {val} {data}\")\n",
      "Message: 'config_cb model/num_parameters 3261377536 None'\n",
      "Arguments: ()\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4418' max='4418' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4418/4418 3:14:56, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.898700</td>\n",
       "      <td>0.970238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.930709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.677300</td>\n",
       "      <td>0.932519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.666300</td>\n",
       "      <td>0.925750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.654700</td>\n",
       "      <td>0.921676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.928431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.638900</td>\n",
       "      <td>0.915237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.907603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.930552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.532400</td>\n",
       "      <td>0.923371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.928714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.920001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>0.920595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.925150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.925274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.503200</td>\n",
       "      <td>0.925303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
      "    self.flush()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 95] Operation not supported\n",
      "Call stack:\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3083, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/IPython/core/events.py\", line 82, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/cs769_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 613, in _post_run_cell_hook\n",
      "    self._logger.info(\"resuming backend\")\n",
      "Message: 'resuming backend'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\n",
    "    #     \"--difficulty\",\n",
    "    #     choices=[\"easy\",\"medium\",\"hard\"],\n",
    "    #     required=True,\n",
    "    #     help=\"Which subset (easy/medium/hard) to fine-tune\"\n",
    "    # )\n",
    "    # args = parser.parse_args()\n",
    "    # difficulty = args.difficulty\n",
    "    difficulty = 'hard'\n",
    "\n",
    "    # hack to handle data errors while using map function\n",
    "    if difficulty == 'easy':\n",
    "        easy_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset1')))\n",
    "        train_dataset = easy_data.map(format_chat_template)\n",
    "    elif difficulty == 'medium':\n",
    "        medium_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset2')))\n",
    "        train_dataset = medium_data.map(format_chat_template)\n",
    "    elif difficulty == 'hard':\n",
    "        hard_data = Dataset.from_pandas(pd.DataFrame(load_from_disk('./json_to_hf/subset3')))\n",
    "        train_dataset = hard_data.map(format_chat_template)\n",
    "\n",
    "    val_data = load_dataset(dataset_name, split='validation', trust_remote_code=True)\n",
    "    val_dataset = val_data.map(format_chat_template)\n",
    "\n",
    "    # Use existing global bnb_config defined earlier\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        token=HF_TOKEN\n",
    "    )\n",
    "    base_model = prepare_model_for_kbit_training(base_model)\n",
    "    modules = find_all_linear_names(base_model)\n",
    "    peft_config, peft_model = create_lora_model(base_model, difficulty, modules)\n",
    "\n",
    "    train_adapter(\n",
    "            model_dir=\"LoRA‐MedQA\",\n",
    "            run_name=f'Lora_{difficulty}',\n",
    "            bnb_config=bnb_config,\n",
    "            difficulty_level=difficulty,\n",
    "            train_data=train_dataset,\n",
    "            val_data=val_dataset,\n",
    "            peft_model=peft_model,\n",
    "            peft_config=peft_config\n",
    "        )\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs769_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
